import gradio as gr

if __name__ == "__main__":
    block = gr.Blocks()
    with block as demo:
        gr.Markdown("""<h1><center>LangChain-ChatLLM-Webui</center></h1>
        <center><font size=3>
        æœ¬é¡¹ç›®åŸºäºLangChainå’Œå¤§å‹è¯­è¨€æ¨¡å‹ç³»åˆ—æ¨¡å‹, æä¾›åŸºäºæœ¬åœ°çŸ¥è¯†çš„è‡ªåŠ¨é—®ç­”åº”ç”¨. <br>
        ç›®å‰é¡¹ç›®æä¾›åŸºäº<a href='https://github.com/THUDM/ChatGLM-6B' target="_blank">ChatGLM-6B </a>çš„LLMå’ŒåŒ…æ‹¬GanymedeNil/text2vec-large-chineseã€nghuyong/ernie-3.0-base-zhã€nghuyong/ernie-3.0-nano-zhåœ¨å†…çš„å¤šä¸ªEmbeddingæ¨¡å‹, æ”¯æŒä¸Šä¼  txtã€docxã€mdã€pdfç­‰æ–‡æœ¬æ ¼å¼æ–‡ä»¶. <br>
        åç»­å°†æä¾›æ›´åŠ å¤šæ ·åŒ–çš„LLMã€Embeddingå’Œå‚æ•°é€‰é¡¹ä¾›ç”¨æˆ·å°è¯•, æ¬¢è¿å…³æ³¨<a href='https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui' target="_blank">Githubåœ°å€</a>.
        </center></font>
        """)
        with gr.Row():
            with gr.Column(scale=1):
                model_choose = gr.Accordion("æ¨¡å‹é€‰æ‹©")
                with model_choose:
                    large_language_model = gr.Dropdown(
                        ["llm1","llm2"],
                        label="large language model",
                        value="llm1")

                    embedding_model = gr.Dropdown(
                        ["emb1","emb2"],
                        label="Embedding model",
                        value="emb1")
                    load_model_button = gr.Button("é‡æ–°åŠ è½½æ¨¡å‹")
                model_argument = gr.Accordion("æ¨¡å‹å‚æ•°é…ç½®")
                with model_argument:
                    top_k = gr.Slider(1,
                                      10,
                                      value=6,
                                      step=1,
                                      label="vector search top k",
                                      interactive=True)
                    history_len = gr.Slider(0,
                                            5,
                                            value=3,
                                            step=1,
                                            label="history len",
                                            interactive=True)
                    temperature = gr.Slider(0,
                                            1,
                                            value=0.01,
                                            step=0.01,
                                            label="temperature",
                                            interactive=True)
                    top_p = gr.Slider(0,
                                      1,
                                      value=0.9,
                                      step=0.1,
                                      label="top_p",
                                      interactive=True)

                file = gr.File(label='è¯·ä¸Šä¼ çŸ¥è¯†åº“æ–‡ä»¶',
                               file_types=['.txt', '.md', '.docx', '.pdf'])

            with gr.Column(scale=4):
                chatbot = gr.Chatbot([[None, None]],
                                     label='ChatLLM').style(height=750)
                message = gr.Textbox(label='è¯·è¾“å…¥é—®é¢˜')
                state = gr.State()

                with gr.Row():
                    clear_history = gr.Button("ğŸ§¹ æ¸…é™¤å†å²å¯¹è¯")
                    send = gr.Button("ğŸš€ å‘é€")
        gr.Markdown("""æé†’ï¼š<br>
        1. ä½¿ç”¨æ—¶è¯·å…ˆä¸Šä¼ è‡ªå·±çš„çŸ¥è¯†æ–‡ä»¶ï¼Œå¹¶ä¸”æ–‡ä»¶ä¸­ä¸å«æŸäº›ç‰¹æ®Šå­—ç¬¦ï¼Œå¦åˆ™å°†è¿”å›error. <br>
        2. æœ‰ä»»ä½•ä½¿ç”¨é—®é¢˜ï¼Œè¯·é€šè¿‡[Github IssueåŒº](https://github.com/thomas-yanxin/LangChain-ChatGLM-Webui/issues)è¿›è¡Œåé¦ˆ. <br>
        """)
    # threads to consume the request
    demo.queue(concurrency_count=3) \
        .launch(server_name='0.0.0.0', # ip for listening, 0.0.0.0 for every inbound traffic, 127.0.0.1 for local inbound
                server_port=7860, # the port for listening
                show_api=False, # if display the api document
                share=True, # if register a public url
                inbrowser=True) # if browser would be open automatically
